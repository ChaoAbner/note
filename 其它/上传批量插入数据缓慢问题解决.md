在上传资源文件的时候，如果数据量大于3000以上，会发现响应变得很慢，要几十秒才能返回

甚至给前端返回了500，服务器错误。

## 程序分析

![image-20201209145202072](http://img.fosuchao.com/image-20201209145202072.png)

插入资源这个函数中主要涉及了以下几个操作

1. 判断资源是否存在
2. 新建资源包
3. 构建param
4. 批量插入资源数据（重点）
5. 更新资源数量（无关）

> todo 整个函数加了@Transactional注解（声明式事务）去保证事务，但是函数中涉及了查询操作，应该使用编程式事务进行改进

## 测试每个操作花费时间

调用接口插入5000数据，并在程序中进行日志打印，记录程序执行花费的时间

![image-20201209144254379](http://img.fosuchao.com/image-20201209144254379.png)

可以看到，主要的耗时就是插入数据的时候所消耗的

## datagrip中执行SQL

测试5000行直接使用SQL进行批量插入

![image-20201209150557731](http://img.fosuchao.com/image-20201209150557731.png)

花费时间**1s65ms**

从以上的信息可以发现，使用insert进行批量插入的速度是很快的，那么问题就出在批量插入数据代码执行过程中

![image-20201209150414041](http://img.fosuchao.com/image-20201209150414041.png)

## 分析问题

有问题的代码如下

![image-20201209150454921](http://img.fosuchao.com/image-20201209150454921.png)

其实就是通过MyBatis的foreach标签生成动态SQL，最终得到形如下面的SQL，预编译后将数据填充上去，执行的话还是跟上面datagrip执行的效果是一样的

![image-20201209150800769](http://img.fosuchao.com/image-20201209150800769.png)

### 猜测问题原因

Mybatis 在解析 <forEach> 的时候，因为需要循环解析 #{} 之类的占位符，foreach 的集合越大，PreparedStatement越长，对于占位符和参数的映射尤其耗时。并且，查阅相关[资料](https://www.red-gate.com/simple-talk/sql/performance/comparing-multiple-rows-insert-vs-single-row-insert-with-three-data-load-methods/)可知，values的增长与所需的解析时间，是呈指数型增长的。

![image-20201209153315354](http://img.fosuchao.com/image-20201209153315354.png)

**如果非要用<forEach>的方式来插入，可以分批进行插入，最好把数据量控制在如图100个数据左右提升性能的方式。**

而实际上，MyBatis文档中写批量插入的时候，是推荐使用jdbc批处理的方式：

具体参考[链接](https://mybatis.org/mybatis-dynamic-sql/docs/insert.html)

![image-20201209161743123](http://img.fosuchao.com/image-20201209161743123.png)

![image-20201209161808713](http://img.fosuchao.com/image-20201209161808713.png)

如果发现使用批处理并没有提升插入效率，注意在JDBC配置中的URL字段参数中需要新增一个参数：**rewriteBatchedStatements=true**

![image-20201210083307875](http://img.fosuchao.com/image-20201210083307875.png)

## 参考资料

https://www.jianshu.com/p/0f4b7bc4d22c

https://blog.csdn.net/huanghanqian/article/details/83177178

https://mybatis.org/mybatis-dynamic-sql/docs/insert.html