# TCP连接的异常断开

> 以上都是在理想的情况下发生的，理想状态下，一个TCP连接可以被长期保持。但是现实总是很骨感，在保持TCP连接的过程中很可能出现各种意外的情况，比如网络故障，客户端崩溃或者异常重启，在这种情况下，如果服务端没有及时清理这些连接，服务端将发生连接泄露，直至服务端资源耗尽拒绝提供服务（connection refused exception）。因此在实际应用中，服务器端需要采取相应的方法来探测TCP连接是否已经断连。探测的原理就是心跳机制，可以是应用层面的心跳，也可以是第三方的心跳，但是绝大部分类Unix系统均在TCP中提供了相应的心跳检测功能（虽然并不是TCP规范中的一部分）。

## 服务器进程终止

​    我们启动客户/服务器对，然后杀死子进程（模拟服务器进程崩溃的情形，我们可从中查看客户端将发生什么）。

​    1：在同一个主机上启动服务器和客户，并在客户上输入一行文本，以验证一切正常。正常情况下，改行文本将由服务器回射给客户。

​    2：找到服务器子进程的ID，通过kill命令杀死它。作为进程终止处理的部分工作，子进程中所有打开着的描述字都被关闭。这就导致向客户发送一个FIN，而客户TCP则响应以一个ACK。这就是TCP连接终止的前一半工作。

​    3：子进程终止时，内核将给父进程递交SIGCHLD信号。

​    4：客户上没有发生任何特殊之事。客户TCP接受来自服务器TCP的FIN并响应一个ACK，然后问题是客户进程此时阻塞在fgets调用上，等待从终端接受一行文本。它是看不到这个FIN的。

​    5：此时我们如果运行netstat命令，可以看到如下的套接口的状态：

​    [![qj1](https://images0.cnblogs.com/blog/166580/201307/03205630-5fde1f4ee74a4b25acc2f2435f708cf8.jpg)](https://images0.cnblogs.com/blog/166580/201307/03205629-2cb06a98606f4064aa0789438a11c792.jpg)

​    FIN_WAIT2即为我们杀掉的那个子进程的，因为我们知道主动关闭的那端在发送完fin并接受对端的ack后将进入fin_wait2状态，此时它在等待对端的fin。

​    6：现在我们在客户上在输入一行文本，我们可以看到如下的输出：

​    [![qj2](https://images0.cnblogs.com/blog/166580/201307/03205631-d07c50b2c9f4430caa426fb8cf13eaa4.jpg)](https://images0.cnblogs.com/blog/166580/201307/03205631-86f2fe56c199427fb0cb713d3322e61b.jpg)

​    当我们输入“after server close”时，客户TCP接着把数据发送给服务器，TCP允许这么做，因为客户TCP接受到FIN只是表示服务器进程已关闭了连接的服务端，从而不再往其中发送任何数据而已。FIN的接受并没有告知客户TCP服务器进程已经终止（在这个例子中它缺失是终止了）。当服务器TCP接收到来自客户的数据时，既然先前打开那个套接口的进程已经终止，于是响应一个RST。

​    7：然而客户进程看不到这个RST，因为它在调用write后立即调用read，并且由于第2步中接收到FIN，所调用的read立即返回0（表示）EOF。我们的客户此时并未预期收到EOF，于是以出错信息“server term prematurely.”（服务器过早终止）退出。

​    8：当客户终止时，它所有打开着的描述字都被关闭。

> ​    *我们的上述讨论还取决于程序的时序。客户调用read既可能发生在服务器的RST被客户收到之前，也可能发生在收到之后。如果read发生在收到RST之前（如本例子所示），那么结果是客户得到一个未预期的EOF；否则结果是由readline返回一个ECONNRESET（“connection reset by peer”对方复位连接）错误。*

​    本例子的问题在于：当FIN到达套接口时，客户正阻塞在fgets调用上。客户实际上在应对两个描述字——套接口和用户输入，它不能单纯阻塞在这两个源中某个特定源的输入上，而是应该阻塞在其任何一个源的输入上。（可用select等io复用的函数实现）

## 服务器主机崩溃

​    我们接着查看当服务器主机崩溃时会发生什么。为了模拟这种情形，我们需要在不同的机器上运行客户与服务器，在首次确认客户服务器能正常工作后，我们从网络上断开服务器主机，并在客户上再输入一行文本。这里同时也模拟了当客户发送数据时服务器主机不可达的情形（机建立连接后某些中间路由器不工作）

​     1：**当服务器主机崩溃时，已有的网络连接上发不出任何东西**。这里我们假设的是主机崩溃，而不是执行了关机命令。

​     2：我们在客户上输入一行文本，**它由write写入内核，再由客户TCP作为一个数据分节送出。客户随后阻塞于read调用，等待服务器的应答**。

​     3：这种情况下，**客户TCP持续重传数据分节，试图从服务器上接受一个ACK**。（源自Berkeley的实现**重传该数据分节12次，共等待约9分钟才放弃重传**。）当客户TCP最终放弃时（假设这段时间内，服务器主机没有重新启动或者如果是服务器主机为崩溃但从网络上不可达的情况，那么假设主机仍然不可达），返回客户进程一个错误。既然客户阻塞在readline调用上，该调用将返回一个错误。假设服务器已崩溃，从而对客户的数据分节根本没有响应，那么所返回的错误是ETIMEDOUT。然而如果某个中间路由器判定服务器主机已不可达，从而响应以一个“destination unreachable”，那么所返回的错误是EHOSTUNREACH或ENETUNREACH。

​     尽管我们的客户最后还是发现对端主机已崩溃或不可达，不过**有时候我们需要更快地检测出这种情况，而不是不得不等待9分钟。所用的方法就是对read调用设置一个超时**。

​     另外我们刚讨论的情形只有在向服务器主机发送数据时，才能检测出它已经崩溃，如果我们**不主动发送主句也想检测出服务器主机的崩溃，那么就需要用到`SO_KEEPALIVE`这个套接口选项。**    

## 服务器主机崩溃后重启

​    在前一节的分析中，当我们发送数据时，服务器主机仍然处于崩溃状态；这节，我们将在发送数据前重新启动崩溃了的服务器主机。模拟这种情况的简单方法就是：建立连接，再从网络上端口服务器主机，将它关机后再重启，最后把它重新连接到网络中。

​    如前一节所述，如果在服务器主机崩溃时客户不主动给服务器发送数据，那么客户不会知道服务器主机已经崩溃。所发生的步骤如下：

​    1：启动客户服务器，在客户上输入一行文本已确认连接已建立。

​    2：服务器主机崩溃并重启。

​    3：在客户上输入一行文本，它将作为一个TCP数据分节发送到服务器主机。

​    4：当服务器主机崩溃后重启时，它的TCP丢失了崩溃前的所有连接信息，因此服务器TCP对于所收到的来自客户的数据分节响应以一个RST。

​    5：当客户TCP收到该RST时，客户正阻塞于read调用，导致该调用返回ECONNRESET错误。

## 服务器主机关机

   这节我们看看当服务器关机时将会发生什么。

​    Unix系统关机时，init进程通常先给所有进程发送SIGTERM信号（该信号可被捕获），再等待一段固定的时间（一般在5~20秒之间），然后给所有仍在运行的进程发送SIGKILL信号（该信号不能被捕获）。这么做是留给所有运行中的进程一小段时间来清除和终止。如果我们不捕获SIGTERM信号并终止，我们的服务器将由SIGKILL信号终止。当服务器进程终止时，它的所有打开着的描述字都被关闭，随后发生的步骤与第一节中讨论过的一样。正如第一节中所述的情形，我们必须在客户中使用select或poll函数，使得服务器进程的终止已经发生，客户马上检测到。

## 客户端程序崩溃或异常退出

当客户端程序因未知原因崩溃或异常退出后，操作系统会给服务端发送一条RST消息，阻塞模型下，服务端内核无法主动通知应用层出错，只有应用层主动调用read()或者write()这样的IO系统调用时，内核才会利用出错来通知应用层对端RST（Linux系统报Connection reset by peer）。非阻塞模型下，服务端select或者epoll会返回sockfd可读,应用层对其进行读取时，read()会报错RST。

哪些情况下，会收到来自对端的RST消息呢。

connect一个不存在的端口，客户端会收到一条RST，报错Connection refused；
程序崩溃或异常退出，会向对端发送。
对端断电重启，send数据时会收到来自对端的RST。
close(sockfd)时，直接丢弃接收缓冲区未读取的数据，并给对方发一个RST。这个是由SO_LINGER选项来控制的；
TCP socket在任何状态下，只要收到RST包，即可释放连接资源。

## 客户端断电或网络异常

如果客户端断电或网络异常，并且连接通道内没有任何数据交互，服务端是感知不到客户端掉线的，此时需要借助心跳机制来感知这种状况，一般的做法是，服务端往对端发送一个心跳包并启动一个超时定时器，如果能正确收到对端的回应，说明在线，如果超时，可以进行一系列操作，比如重试、关闭连接等等。

**keep alive or heart beart**
借鉴一下大神的文章
**很多人都知道TCP并不会去主动检测连接的丢失，这意味着，如果双方不产生交互，那么如果网络断了或者有一方机器崩溃，另外一方将永远不知道连接已经不可用了。检测连接是否丢失的方法大致有两种：keepalive和heart-beat。**

Keepalive是很多的TCP实现提供的一种机制，它允许连接在空闲的时候双方会发送一些特殊的数据段，并通过响应与否来判断连接是否还存活着（所谓keep~~alive）。我曾经写过一篇关于keepalive的blog ，但后来我也发现，其实keepalive在实际的应用中并不常见。为何如此？这得归结于keepalive设计的初衷。Keepalive适用于清除死亡时间比较长的连接。

比如这样的场景：一个用户创建tcp连接访问了一个web服务器，当用户完成他执行的操作后，很粗暴的直接拨了网线。这种情况下，这个tcp连接已经断开了，但是web服务器并不知道，它会依然守护着这个连接。如果web server设置了keepalive，那么它就能够在用户断开网线的大概几个小时以后，确认这个连接已经中断，然后丢弃此连接，回收资源。

采用keepalive，它会先要求此连接一定时间没有活动（一般是几个小时），然后发出数据段，经过多次尝试后（每次尝试之间也有时间间隔），如果仍没有响应，则判断连接中断。可想而知，整个周期需要很长的时间。

所以，如前面的场景那样，需要一种方法能够清除和回收那些在系统不知情的情况下死去了很久的连接，keepalive是非常好的选择。

但是，在大部分情况下，特别是分布式环境中，我们需要的是一个能够快速或者实时监控连接状态的机制，这里，heart-beat才是更加合适的方案。

Heart-beat（心跳），按我的理解，它的原理和keepalive非常类似，**都是发送一个信号给对方，如果多次发送都没有响应的话，则判断连接中断**。它们的不同点在于，keepalive是tcp实现中内建的机制，是在创建tcp连接时通过设置参数启动keepalive机制；而**heart-beat则需要在tcp之上的应用层实现**。一个简单的heart-beat实现一般测试连接是否中断采用的时间间隔都比较短，可以很快的决定连接是否中断。并且，由于是在应用层实现，因为可以自行决定当判断连接中断后应该采取的行为，而keepalive在判断连接失败后只会将连接丢弃。

关于heart-beat，一个非常有趣的问题是，应该在传输真正数据的连接中发送心跳信号，还是可以专门创建一个发送“心跳”信号的连接。比如说，A，B两台机器之间通过连接m来传输数据，现在为了能够检测A，B之间的连接状态，我们是应该在连接m中传输心跳信号，还是创建新的连接n来专门传输心跳呢？我个人认为两者皆可。如果担心的是端到端的连接状态，那么就直接在该条连接中实现心跳。但很多时候，关注的是网络状况和两台主机间的连接状态，这种情况下， 创建专门的心跳连接也未尝不可。

## Socket感知连接断开

**正常情况**
客户端正常关闭连接：

//发送FIN消息，说明客户端已经没有数据发送，服务端read时会返回-1或者null
`socket.shutdownOutput();`
//默认的SO_LINGER参数，客户端发送FIN消息，服务端read时会返回-1或者null
`socket.close();`
//设置了立即关闭，客户端发送RST消息，服务端`read`时会报`connection rest by peer`。
`socket.close();`

**非正常情况**
客户端程序崩溃或异常退出：服务端read时会报connection rest by peer。
断电重启：服务端发送心跳信息时，会收到客户端的RST消息，调用read时会报connection rest by peer。
断电或网络中断：服务端发送心跳信息后超时。

